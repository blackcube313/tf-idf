{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import csr_matrix\n",
    "import math\n",
    "import operator\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "     'this is the first document',\n",
    "     'this document is the second document',\n",
    "     'and this is the third one',\n",
    "     'is this the first document',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
     ]
    }
   ],
   "source": [
    "def fit(dataset):\n",
    "    # To find unique words in corpus\n",
    "    storage_set = set() # set only keeps unique entries\n",
    "    if isinstance(dataset,(list,)):\n",
    "        for document in dataset:\n",
    "            for word in document.split(\" \"):\n",
    "                storage_set.add(word)\n",
    "        storage_set = sorted(list(storage_set))\n",
    "        vocab = {j:i for i,j in enumerate(storage_set)}\n",
    "        return vocab\n",
    "    else:\n",
    "        print(\"you need to pass list of sentance\")\n",
    "\n",
    "vocab =  fit(corpus)\n",
    "# print(vocab)\n",
    "vocab_list = list(vocab.keys())\n",
    "print(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and': 1.916290731874155, 'document': 1.2231435513142097, 'first': 1.5108256237659907, 'is': 1.0, 'one': 1.916290731874155, 'second': 1.916290731874155, 'the': 1.0, 'third': 1.916290731874155, 'this': 1.0}\n"
     ]
    }
   ],
   "source": [
    "def computeIDF(vocabulary, dataset):\n",
    "    # To find Inverse Document Frequency of unique words / vocabulary\n",
    "    idf_val = dict()\n",
    "    for word in vocabulary:\n",
    "        count = 0 # here we collect the term t as it appears in different documents\n",
    "        for doc in dataset:\n",
    "            if word in doc.split(' '):\n",
    "                count += 1\n",
    "                \n",
    "        value = 1 + math.log ((1 + (len(dataset))) / (1 + count))\n",
    "        # Formula adjusted to sk_learn\n",
    "        idf_val[word] = value\n",
    "    return idf_val\n",
    "\n",
    "IDF = computeIDF(vocab_list, corpus)\n",
    "print(IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      " 0.38408524 0.         0.38408524]\n"
     ]
    }
   ],
   "source": [
    "def transform(dataset,vocabulary, idf_values):\n",
    "    # To find tfidf values and change it to matrix\n",
    "    rows = []\n",
    "    columns = []\n",
    "    values = []\n",
    "    for idx, doc in enumerate(dataset):\n",
    "        N = len([word for word in doc.split(' ')]) # Number of documents in corpus\n",
    "        word_freq = dict(Counter(doc.split(' ')))\n",
    "        tf = {key:(val/N) for key,val in word_freq.items()}\n",
    "        for word, norm_freq in tf.items():\n",
    "            if len(word) < 2:\n",
    "                continue;\n",
    "            col_index = vocabulary.get(word, -1)\n",
    "            if col_index !=-1:\n",
    "                rows.append(idx)\n",
    "                columns.append(col_index)\n",
    "                idf = idf_values[word]\n",
    "                values.append(norm_freq * idf) # tfidf values\n",
    "    return normalize(csr_matrix((values, (rows,columns)), shape=(len(dataset),len(vocab))), norm='l2');\n",
    "\n",
    "\n",
    "output = (transform(dataset=corpus, vocabulary=vocab, idf_values=IDF).toarray())\n",
    "print(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 9)\n"
     ]
    }
   ],
   "source": [
    "print(transform(corpus, vocab, IDF).shape)\n",
    "# print(transform(corpus, vocab, IDF).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t0.4697913855799205\n",
      "  (0, 2)\t0.580285823684436\n",
      "  (0, 3)\t0.3840852409148149\n",
      "  (0, 6)\t0.3840852409148149\n",
      "  (0, 8)\t0.3840852409148149\n"
     ]
    }
   ],
   "source": [
    "output = (transform(dataset=corpus, vocabulary=vocab, idf_values=IDF))\n",
    "print(output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement max features functionality:\n",
    "\n",
    "As a part of this task you have to modify your fit and transform functions so that your vocab will contain only 50 terms with top idf scores.\n",
    "\n",
    "This task is similar to your previous task, just that here your vocabulary is limited to only top 50 features names based on their idf values. Basically your output will have exactly 50 columns and the number of rows will depend on the number of documents you have in your corpus.\n",
    "\n",
    "Here you will be give a pickle file, with file name cleaned_strings. You would have to load the corpus from this file and use it as input to your tfidf vectorizer.\n",
    "\n",
    "Steps to approach this task:\n",
    "\n",
    "You would have to write both fit and transform methods for your custom implementation of tfidf vectorizer, just like in the previous task. Additionally, here you have to limit the number of features generated to 50 as described above.\n",
    "\n",
    "Now sort your vocab based in descending order of idf values and print out the words in the sorted voacb after you fit your data. Here you should be getting only 50 terms in your vocab. And make sure to print idf values for each term in your vocab.\n",
    "\n",
    "Make sure the output of your implementation is a sparse matrix. Before generating the final output, you need to normalize your sparse matrix using L2 normalization. You can refer to this link https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.normalize.html\n",
    "\n",
    "Now check the output of a single document in your collection of documents, you can convert the sparse matrix related only to that document into dense matrix and print it. And this dense matrix should contain 1 row and 50 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in corpus =  746\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('cleaned_strings', 'rb') as f:\n",
    "    corpus = pickle.load(f)\n",
    "    \n",
    "# printing the length of the corpus loaded\n",
    "print(\"Number of documents in corpus = \",len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aailiyah': 0, 'abandoned': 1, 'ability': 2, 'abroad': 3, 'absolutely': 4, 'abstruse': 5, 'abysmal': 6, 'academy': 7, 'accents': 8, 'accessible': 9, 'acclaimed': 10, 'accolades': 11, 'accurate': 12, 'accurately': 13, 'accused': 14, 'achievement': 15, 'achille': 16, 'ackerman': 17, 'act': 18, 'acted': 19, 'acting': 20, 'action': 21, 'actions': 22, 'actor': 23, 'actors': 24, 'actress': 25, 'actresses': 26, 'actually': 27, 'adams': 28, 'adaptation': 29, 'add': 30, 'added': 31, 'addition': 32, 'admins': 33, 'admiration': 34, 'admitted': 35, 'adorable': 36, 'adrift': 37, 'adventure': 38, 'advise': 39, 'aerial': 40, 'aesthetically': 41, 'affected': 42, 'affleck': 43, 'afraid': 44, 'africa': 45, 'afternoon': 46, 'age': 47, 'aged': 48, 'ages': 49, 'ago': 50, 'agree': 51, 'agreed': 52, 'aimless': 53, 'air': 54, 'aired': 55, 'akasha': 56, 'akin': 57, 'alert': 58, 'alexander': 59, 'alike': 60, 'allison': 61, 'allow': 62, 'allowing': 63, 'almost': 64, 'along': 65, 'alongside': 66, 'already': 67, 'also': 68, 'although': 69, 'always': 70, 'amateurish': 71, 'amaze': 72, 'amazed': 73, 'amazing': 74, 'amazingly': 75, 'america': 76, 'american': 77, 'americans': 78, 'among': 79, 'amount': 80, 'amusing': 81, 'amust': 82, 'anatomist': 83, 'angel': 84, 'angela': 85, 'angeles': 86, 'angelina': 87, 'angle': 88, 'angles': 89, 'angry': 90, 'anguish': 91, 'angus': 92, 'animals': 93, 'animated': 94, 'animation': 95, 'anita': 96, 'ann': 97, 'anne': 98, 'anniversary': 99, 'annoying': 100, 'another': 101, 'anthony': 102, 'antithesis': 103, 'anyone': 104, 'anything': 105, 'anyway': 106, 'apart': 107, 'appalling': 108, 'appealing': 109, 'appearance': 110, 'appears': 111, 'applauded': 112, 'applause': 113, 'appreciate': 114, 'appropriate': 115, 'apt': 116, 'argued': 117, 'armageddon': 118, 'armand': 119, 'around': 120, 'array': 121, 'art': 122, 'articulated': 123, 'artiness': 124, 'artist': 125, 'artistic': 126, 'artless': 127, 'arts': 128, 'aside': 129, 'ask': 130, 'asleep': 131, 'aspect': 132, 'aspects': 133, 'ass': 134, 'assante': 135, 'assaulted': 136, 'assistant': 137, 'astonishingly': 138, 'astronaut': 139, 'atmosphere': 140, 'atrocious': 141, 'atrocity': 142, 'attempt': 143, 'attempted': 144, 'attempting': 145, 'attempts': 146, 'attention': 147, 'attractive': 148, 'audience': 149, 'audio': 150, 'aurv': 151, 'austen': 152, 'austere': 153, 'author': 154, 'average': 155, 'aversion': 156, 'avoid': 157, 'avoided': 158, 'award': 159, 'awarded': 160, 'awards': 161, 'away': 162, 'awesome': 163, 'awful': 164, 'awkwardly': 165, 'aye': 166, 'b': 167, 'baaaaaad': 168, 'babbling': 169, 'babie': 170, 'baby': 171, 'babysitting': 172, 'back': 173, 'backdrop': 174, 'backed': 175, 'bad': 176, 'badly': 177, 'bag': 178, 'bailey': 179, 'bakery': 180, 'balance': 181, 'balanced': 182, 'ball': 183, 'ballet': 184, 'balls': 185, 'band': 186, 'barcelona': 187, 'barely': 188, 'barking': 189, 'barney': 190, 'barren': 191, 'based': 192, 'basic': 193, 'basically': 194, 'bat': 195, 'bates': 196, 'baxendale': 197, 'bear': 198, 'beautiful': 199, 'beautifully': 200, 'bec': 201, 'became': 202, 'bechard': 203, 'become': 204, 'becomes': 205, 'began': 206, 'begin': 207, 'beginning': 208, 'behind': 209, 'behold': 210, 'bela': 211, 'believable': 212, 'believe': 213, 'believed': 214, 'bell': 215, 'bellucci': 216, 'belly': 217, 'belmondo': 218, 'ben': 219, 'bendingly': 220, 'bennett': 221, 'bergen': 222, 'bertolucci': 223, 'best': 224, 'better': 225, 'betty': 226, 'beware': 227, 'beyond': 228, 'bible': 229, 'big': 230, 'biggest': 231, 'billy': 232, 'biographical': 233, 'bipolarity': 234, 'bit': 235, 'bitchy': 236, 'black': 237, 'blah': 238, 'blake': 239, 'bland': 240, 'blandly': 241, 'blare': 242, 'blatant': 243, 'blew': 244, 'blood': 245, 'blown': 246, 'blue': 247, 'blush': 248, 'boasts': 249, 'bob': 250, 'body': 251, 'bohemian': 252, 'boiling': 253, 'bold': 254, 'bombardments': 255, 'bond': 256, 'bonding': 257, 'bonus': 258, 'bonuses': 259, 'boobs': 260, 'boogeyman': 261, 'book': 262, 'boost': 263, 'bop': 264, 'bordered': 265, 'borderlines': 266, 'borders': 267, 'bore': 268, 'bored': 269, 'boring': 270, 'borrowed': 271, 'boss': 272, 'bother': 273, 'bothersome': 274, 'bought': 275, 'box': 276, 'boyfriend': 277, 'boyle': 278, 'brain': 279, 'brainsucking': 280, 'brat': 281, 'breaking': 282, 'breeders': 283, 'brevity': 284, 'brian': 285, 'brief': 286, 'brigand': 287, 'bright': 288, 'brilliance': 289, 'brilliant': 290, 'brilliantly': 291, 'bring': 292, 'brings': 293, 'broad': 294, 'broke': 295, 'brooding': 296, 'brother': 297, 'brutal': 298, 'buddy': 299, 'budget': 300, 'buffalo': 301, 'buffet': 302, 'build': 303, 'builders': 304, 'buildings': 305, 'built': 306, 'bullock': 307, 'bully': 308, 'bunch': 309, 'burton': 310, 'business': 311, 'buy': 312, 'cable': 313, 'cailles': 314, 'california': 315, 'call': 316, 'called': 317, 'calls': 318, 'came': 319, 'cameo': 320, 'camera': 321, 'camerawork': 322, 'camp': 323, 'campy': 324, 'canada': 325, 'cancan': 326, 'candace': 327, 'candle': 328, 'cannot': 329, 'cant': 330, 'captain': 331, 'captured': 332, 'captures': 333, 'car': 334, 'card': 335, 'cardboard': 336, 'cardellini': 337, 'care': 338, 'carol': 339, 'carrell': 340, 'carries': 341, 'carry': 342, 'cars': 343, 'cartoon': 344, 'cartoons': 345, 'case': 346, 'cases': 347, 'cast': 348, 'casted': 349, 'casting': 350, 'cat': 351, 'catchy': 352, 'caught': 353, 'cause': 354, 'ceases': 355, 'celebration': 356, 'celebrity': 357, 'celluloid': 358, 'centers': 359, 'central': 360, 'century': 361, 'certain': 362, 'certainly': 363, 'cg': 364, 'cgi': 365, 'chalkboard': 366, 'challenges': 367, 'chance': 368, 'change': 369, 'changes': 370, 'changing': 371, 'channel': 372, 'character': 373, 'characterisation': 374, 'characters': 375, 'charisma': 376, 'charismatic': 377, 'charles': 378, 'charlie': 379, 'charm': 380, 'charming': 381, 'chase': 382, 'chasing': 383, 'cheap': 384, 'cheaply': 385, 'check': 386, 'checking': 387, 'cheek': 388, 'cheekbones': 389, 'cheerfull': 390, 'cheerless': 391, 'cheesiness': 392, 'cheesy': 393, 'chemistry': 394, 'chick': 395, 'child': 396, 'childhood': 397, 'children': 398, 'childrens': 399, 'chills': 400, 'chilly': 401, 'chimp': 402, 'chodorov': 403, 'choice': 404, 'choices': 405, 'choked': 406, 'chosen': 407, 'chow': 408, 'christmas': 409, 'christopher': 410, 'church': 411, 'cinema': 412, 'cinematic': 413, 'cinematographers': 414, 'cinematography': 415, 'circumstances': 416, 'class': 417, 'classic': 418, 'classical': 419, 'clear': 420, 'clearly': 421, 'clever': 422, 'clich': 423, 'cliche': 424, 'clients': 425, 'cliff': 426, 'climax': 427, 'close': 428, 'closed': 429, 'clothes': 430, 'club': 431, 'co': 432, 'coach': 433, 'coal': 434, 'coastal': 435, 'coaster': 436, 'coherent': 437, 'cold': 438, 'cole': 439, 'collect': 440, 'collective': 441, 'colored': 442, 'colorful': 443, 'colours': 444, 'columbo': 445, 'come': 446, 'comedic': 447, 'comedy': 448, 'comes': 449, 'comfortable': 450, 'comforting': 451, 'comical': 452, 'coming': 453, 'commands': 454, 'comment': 455, 'commentary': 456, 'commented': 457, 'comments': 458, 'commercial': 459, 'community': 460, 'company': 461, 'compelling': 462, 'competent': 463, 'complete': 464, 'completed': 465, 'completely': 466, 'complex': 467, 'complexity': 468, 'composed': 469, 'composition': 470, 'comprehensible': 471, 'compromise': 472, 'computer': 473, 'concentrate': 474, 'conception': 475, 'conceptually': 476, 'concerning': 477, 'concerns': 478, 'concert': 479, 'conclusion': 480, 'condescends': 481, 'confidence': 482, 'configuration': 483, 'confirm': 484, 'conflict': 485, 'confuses': 486, 'confusing': 487, 'connections': 488, 'connery': 489, 'connor': 490, 'conrad': 491, 'consequences': 492, 'consider': 493, 'considerable': 494, 'considered': 495, 'considering': 496, 'considers': 497, 'consistent': 498, 'consolations': 499, 'constant': 500, 'constantine': 501, 'constructed': 502, 'contained': 503, 'containing': 504, 'contains': 505, 'content': 506, 'continually': 507, 'continuation': 508, 'continue': 509, 'continuity': 510, 'continuously': 511, 'contract': 512, 'contrast': 513, 'contributing': 514, 'contributory': 515, 'contrived': 516, 'control': 517, 'controversy': 518, 'convention': 519, 'convey': 520, 'convince': 521, 'convincing': 522, 'convoluted': 523, 'cool': 524, 'coppola': 525, 'cords': 526, 'core': 527, 'corn': 528, 'corny': 529, 'correct': 530, 'cost': 531, 'costs': 532, 'costumes': 533, 'cotton': 534, 'could': 535, 'couple': 536, 'course': 537, 'court': 538, 'courtroom': 539, 'cover': 540, 'cowardice': 541, 'cox': 542, 'crackles': 543, 'crafted': 544, 'crap': 545, 'crash': 546, 'crashed': 547, 'crayon': 548, 'crayons': 549, 'crazy': 550, 'create': 551, 'created': 552, 'creates': 553, 'creative': 554, 'creativity': 555, 'creature': 556, 'credible': 557, 'credit': 558, 'credits': 559, 'crew': 560, 'crime': 561, 'crisp': 562, 'critic': 563, 'critical': 564, 'crocdodile': 565, 'crocs': 566, 'cross': 567, 'crowd': 568, 'crowe': 569, 'cruel': 570, 'cruise': 571, 'cry': 572, 'cult': 573, 'culture': 574, 'curtain': 575, 'custer': 576, 'cute': 577, 'cutest': 578, 'cutie': 579, 'cutouts': 580, 'cuts': 581, 'cutting': 582, 'dads': 583, 'damian': 584, 'damn': 585, 'dance': 586, 'dancing': 587, 'dangerous': 588, 'dark': 589, 'darren': 590, 'daughter': 591, 'daughters': 592, 'day': 593, 'days': 594, 'de': 595, 'dead': 596, 'deadly': 597, 'deadpan': 598, 'deal': 599, 'dealt': 600, 'death': 601, 'debated': 602, 'debbie': 603, 'debits': 604, 'debut': 605, 'decay': 606, 'decent': 607, 'decidely': 608, 'decipher': 609, 'decisions': 610, 'dedication': 611, 'dee': 612, 'deep': 613, 'deeply': 614, 'defensemen': 615, 'defined': 616, 'definitely': 617, 'delete': 618, 'delight': 619, 'delightful': 620, 'delights': 621, 'deliver': 622, 'delivered': 623, 'delivering': 624, 'delivers': 625, 'dependant': 626, 'depending': 627, 'depends': 628, 'depicted': 629, 'depicts': 630, 'depressing': 631, 'depth': 632, 'derivative': 633, 'describe': 634, 'describes': 635, 'desert': 636, 'deserved': 637, 'deserves': 638, 'deserving': 639, 'design': 640, 'designed': 641, 'designer': 642, 'desperately': 643, 'desperation': 644, 'despised': 645, 'despite': 646, 'destroy': 647, 'detailing': 648, 'details': 649, 'develop': 650, 'development': 651, 'developments': 652, 'di': 653, 'diabetic': 654, 'dialog': 655, 'dialogs': 656, 'dialogue': 657, 'diaper': 658, 'dickens': 659, 'difference': 660, 'different': 661, 'dignity': 662, 'dimensional': 663, 'direct': 664, 'directed': 665, 'directing': 666, 'direction': 667, 'director': 668, 'directorial': 669, 'directors': 670, 'disappointed': 671, 'disappointing': 672, 'disappointment': 673, 'disaster': 674, 'disbelief': 675, 'discomfort': 676, 'discovering': 677, 'discovery': 678, 'disgrace': 679, 'disgusting': 680, 'dislike': 681, 'disliked': 682, 'disney': 683, 'disparate': 684, 'distant': 685, 'distinction': 686, 'distorted': 687, 'distract': 688, 'distressed': 689, 'disturbing': 690, 'diving': 691, 'doctor': 692, 'documentaries': 693, 'documentary': 694, 'dodge': 695, 'dogs': 696, 'dollars': 697, 'dominated': 698, 'done': 699, 'donlevy': 700, 'dont': 701, 'doomed': 702, 'dose': 703, 'doubt': 704, 'downs': 705, 'dozen': 706, 'dr': 707, 'dracula': 708, 'draft': 709, 'drag': 710, 'drago': 711, 'drama': 712, 'dramatic': 713, 'drawings': 714, 'drawn': 715, 'dream': 716, 'dreams': 717, 'dreary': 718, 'dribble': 719, 'drift': 720, 'drifting': 721, 'drive': 722, 'drooling': 723, 'dropped': 724, 'dry': 725, 'due': 726, 'duet': 727, 'dull': 728, 'dumb': 729, 'dumbest': 730, 'duper': 731, 'duris': 732, 'dustin': 733, 'dvd': 734, 'dwight': 735, 'dysfunction': 736, 'e': 737, 'earlier': 738, 'early': 739, 'earth': 740, 'easily': 741, 'easy': 742, 'eating': 743, 'ebay': 744, 'ebola': 745, 'eccleston': 746, 'ed': 747, 'edge': 748, 'editing': 749, 'edition': 750, 'educational': 751, 'edward': 752, 'effect': 753, 'effective': 754, 'effects': 755, 'effort': 756, 'efforts': 757, 'egotism': 758, 'eighth': 759, 'eiko': 760, 'either': 761, 'elaborately': 762, 'elderly': 763, 'elegant': 764, 'element': 765, 'elias': 766, 'eloquently': 767, 'else': 768, 'elsewhere': 769, 'embarrassed': 770, 'embarrassing': 771, 'embassy': 772, 'emerge': 773, 'emilio': 774, 'emily': 775, 'emoting': 776, 'emotion': 777, 'emotionally': 778, 'emotions': 779, 'emperor': 780, 'empowerment': 781, 'emptiness': 782, 'empty': 783, 'en': 784, 'enchanting': 785, 'end': 786, 'endearing': 787, 'ended': 788, 'ending': 789, 'endlessly': 790, 'ends': 791, 'energetic': 792, 'energy': 793, 'engaging': 794, 'english': 795, 'enhanced': 796, 'enjoy': 797, 'enjoyable': 798, 'enjoyed': 799, 'enjoyment': 800, 'enough': 801, 'enter': 802, 'enterprise': 803, 'entertained': 804, 'entertaining': 805, 'entire': 806, 'entirely': 807, 'entrance': 808, 'episode': 809, 'episodes': 810, 'equivalent': 811, 'era': 812, 'errol': 813, 'errors': 814, 'escalating': 815, 'escapism': 816, 'especially': 817, 'essence': 818, 'establish': 819, 'established': 820, 'estate': 821, 'estevez': 822, 'etc': 823, 'european': 824, 'evaluate': 825, 'even': 826, 'events': 827, 'ever': 828, 'every': 829, 'everybody': 830, 'everyone': 831, 'everything': 832, 'everywhere': 833, 'evidently': 834, 'evil': 835, 'evinced': 836, 'evokes': 837, 'exactly': 838, 'exaggerating': 839, 'example': 840, 'excellent': 841, 'excellently': 842, 'except': 843, 'exceptional': 844, 'exceptionally': 845, 'excerpts': 846, 'excessively': 847, 'exchange': 848, 'exciting': 849, 'excruciatingly': 850, 'excuse': 851, 'excuses': 852, 'executed': 853, 'exemplars': 854, 'existent': 855, 'existential': 856, 'expansive': 857, 'expect': 858, 'expectations': 859, 'expected': 860, 'expecting': 861, 'experience': 862, 'experiences': 863, 'expert': 864, 'explain': 865, 'explains': 866, 'explanation': 867, 'exploit': 868, 'explorations': 869, 'explosion': 870, 'expression': 871, 'exquisite': 872, 'extant': 873, 'exteriors': 874, 'extraneous': 875, 'extraordinary': 876, 'extremely': 877, 'eye': 878, 'eyes': 879, 'f': 880, 'fabulous': 881, 'face': 882, 'faces': 883, 'facial': 884, 'facing': 885, 'fact': 886, 'factory': 887, 'failed': 888, 'fails': 889, 'fair': 890, 'fairly': 891, 'faithful': 892, 'fall': 893, 'falling': 894, 'falls': 895, 'falsely': 896, 'falwell': 897, 'fame': 898, 'famed': 899, 'family': 900, 'famous': 901, 'fan': 902, 'fanciful': 903, 'fans': 904, 'fantastic': 905, 'fantasy': 906, 'far': 907, 'farce': 908, 'fare': 909, 'fascinated': 910, 'fascinating': 911, 'fascination': 912, 'fashioned': 913, 'fast': 914, 'faster': 915, 'fat': 916, 'father': 917, 'faultless': 918, 'fausa': 919, 'faux': 920, 'favorite': 921, 'favourite': 922, 'fear': 923, 'feature': 924, 'features': 925, 'feel': 926, 'feeling': 927, 'feelings': 928, 'feet': 929, 'feisty': 930, 'fellowes': 931, 'felt': 932, 'female': 933, 'females': 934, 'ferry': 935, 'fest': 936, 'fi': 937, 'fields': 938, 'fifteen': 939, 'fifties': 940, 'fill': 941, 'film': 942, 'filmed': 943, 'filmiing': 944, 'filmmaker': 945, 'filmography': 946, 'films': 947, 'final': 948, 'finale': 949, 'finally': 950, 'financial': 951, 'find': 952, 'finds': 953, 'fine': 954, 'finest': 955, 'fingernails': 956, 'finished': 957, 'fire': 958, 'first': 959, 'fish': 960, 'fishnet': 961, 'fisted': 962, 'fit': 963, 'five': 964, 'flag': 965, 'flakes': 966, 'flaming': 967, 'flashbacks': 968, 'flat': 969, 'flaw': 970, 'flawed': 971, 'flaws': 972, 'fleshed': 973, 'flick': 974, 'flicks': 975, 'florida': 976, 'flowed': 977, 'flying': 978, 'flynn': 979, 'focus': 980, 'fodder': 981, 'follow': 982, 'following': 983, 'follows': 984, 'foolish': 985, 'footage': 986, 'football': 987, 'force': 988, 'forced': 989, 'forces': 990, 'ford': 991, 'foreign': 992, 'foreigner': 993, 'forever': 994, 'forget': 995, 'forgettable': 996, 'forgetting': 997, 'forgot': 998, 'forgotten': 999, 'form': 1000, 'format': 1001, 'former': 1002, 'fort': 1003, 'forth': 1004, 'forwarded': 1005, 'found': 1006, 'four': 1007, 'fox': 1008, 'foxx': 1009, 'frances': 1010, 'francis': 1011, 'frankly': 1012, 'free': 1013, 'freedom': 1014, 'freeman': 1015, 'french': 1016, 'fresh': 1017, 'freshness': 1018, 'friends': 1019, 'friendship': 1020, 'frightening': 1021, 'front': 1022, 'frontier': 1023, 'frost': 1024, 'frustration': 1025, 'fulci': 1026, 'fulfilling': 1027, 'full': 1028, 'fully': 1029, 'fumbling': 1030, 'fun': 1031, 'function': 1032, 'fundamental': 1033, 'funniest': 1034, 'funny': 1035, 'future': 1036, 'fx': 1037, 'g': 1038, 'gabriel': 1039, 'gadget': 1040, 'gain': 1041, 'gake': 1042, 'galley': 1043, 'gallon': 1044, 'game': 1045, 'games': 1046, 'garage': 1047, 'garbage': 1048, 'garbo': 1049, 'garfield': 1050, 'gas': 1051, 'gaudi': 1052, 'gave': 1053, 'gay': 1054, 'geek': 1055, 'gem': 1056, 'general': 1057, 'generally': 1058, 'generates': 1059, 'generic': 1060, 'genius': 1061, 'genre': 1062, 'gently': 1063, 'genuine': 1064, 'george': 1065, 'gerardo': 1066, 'gere': 1067, 'get': 1068, 'gets': 1069, 'getting': 1070, 'ghibili': 1071, 'giallo': 1072, 'gibberish': 1073, 'gifted': 1074, 'giovanni': 1075, 'girl': 1076, 'girlfriend': 1077, 'girls': 1078, 'girolamo': 1079, 'give': 1080, 'given': 1081, 'gives': 1082, 'giving': 1083, 'glad': 1084, 'glance': 1085, 'glasses': 1086, 'gloriously': 1087, 'go': 1088, 'goalies': 1089, 'god': 1090, 'goes': 1091, 'going': 1092, 'gone': 1093, 'gonna': 1094, 'good': 1095, 'gore': 1096, 'goremeister': 1097, 'gorman': 1098, 'gosh': 1099, 'got': 1100, 'goth': 1101, 'gotta': 1102, 'gotten': 1103, 'government': 1104, 'grace': 1105, 'grade': 1106, 'gradually': 1107, 'grainy': 1108, 'granted': 1109, 'graphics': 1110, 'grasp': 1111, 'grates': 1112, 'great': 1113, 'greatest': 1114, 'greatness': 1115, 'green': 1116, 'greenstreet': 1117, 'grew': 1118, 'grim': 1119, 'grimes': 1120, 'gripping': 1121, 'groove': 1122, 'gross': 1123, 'ground': 1124, 'guards': 1125, 'guess': 1126, 'guests': 1127, 'guilt': 1128, 'gung': 1129, 'guy': 1130, 'guys': 1131, 'hackneyed': 1132, 'haggis': 1133, 'hair': 1134, 'hairsplitting': 1135, 'half': 1136, 'halfway': 1137, 'ham': 1138, 'hand': 1139, 'handle': 1140, 'handled': 1141, 'handles': 1142, 'hands': 1143, 'hang': 1144, 'hankies': 1145, 'hanks': 1146, 'happen': 1147, 'happened': 1148, 'happiness': 1149, 'happy': 1150, 'hard': 1151, 'harris': 1152, 'hate': 1153, 'hated': 1154, 'hatred': 1155, 'havilland': 1156, 'hay': 1157, 'hayao': 1158, 'hayworth': 1159, 'hbo': 1160, 'head': 1161, 'heads': 1162, 'hear': 1163, 'heard': 1164, 'heart': 1165, 'hearts': 1166, 'heartwarming': 1167, 'heaven': 1168, 'heche': 1169, 'heels': 1170, 'heist': 1171, 'helen': 1172, 'hell': 1173, 'hellish': 1174, 'helms': 1175, 'help': 1176, 'helping': 1177, 'helps': 1178, 'hence': 1179, 'hendrikson': 1180, 'hernandez': 1181, 'hero': 1182, 'heroes': 1183, 'heroine': 1184, 'heroism': 1185, 'hes': 1186, 'hide': 1187, 'high': 1188, 'higher': 1189, 'highest': 1190, 'highlights': 1191, 'highly': 1192, 'hilarious': 1193, 'hill': 1194, 'hilt': 1195, 'hip': 1196, 'history': 1197, 'hitchcock': 1198, 'ho': 1199, 'hockey': 1200, 'hoffman': 1201, 'hold': 1202, 'holding': 1203, 'holds': 1204, 'holes': 1205, 'hollander': 1206, 'hollow': 1207, 'hollywood': 1208, 'home': 1209, 'homework': 1210, 'honest': 1211, 'honestly': 1212, 'hoot': 1213, 'hope': 1214, 'hopefully': 1215, 'hopeless': 1216, 'horrendous': 1217, 'horrendously': 1218, 'horrible': 1219, 'horrid': 1220, 'horrified': 1221, 'horror': 1222, 'horse': 1223, 'hosting': 1224, 'hot': 1225, 'hour': 1226, 'hours': 1227, 'house': 1228, 'houses': 1229, 'howdy': 1230, 'howe': 1231, 'howell': 1232, 'however': 1233, 'huge': 1234, 'hugo': 1235, 'human': 1236, 'humanity': 1237, 'humans': 1238, 'hummh': 1239, 'humor': 1240, 'humorous': 1241, 'humour': 1242, 'hurt': 1243, 'huston': 1244, 'hype': 1245, 'hypocrisy': 1246, 'idea': 1247, 'idealogical': 1248, 'identified': 1249, 'identifies': 1250, 'identify': 1251, 'idiot': 1252, 'idiotic': 1253, 'idyllic': 1254, 'iffy': 1255, 'im': 1256, 'imaginable': 1257, 'imagination': 1258, 'imaginative': 1259, 'imagine': 1260, 'imdb': 1261, 'imitation': 1262, 'impact': 1263, 'imperial': 1264, 'implausible': 1265, 'important': 1266, 'impossible': 1267, 'impressed': 1268, 'impression': 1269, 'impressive': 1270, 'improved': 1271, 'improvement': 1272, 'improvisation': 1273, 'impulse': 1274, 'inappropriate': 1275, 'incendiary': 1276, 'includes': 1277, 'including': 1278, 'incomprehensible': 1279, 'inconsistencies': 1280, 'incorrectness': 1281, 'incredible': 1282, 'incredibly': 1283, 'indeed': 1284, 'indescribably': 1285, 'indication': 1286, 'indictment': 1287, 'indie': 1288, 'individual': 1289, 'indoor': 1290, 'indulgent': 1291, 'industry': 1292, 'ineptly': 1293, 'inexperience': 1294, 'inexplicable': 1295, 'initially': 1296, 'innocence': 1297, 'insane': 1298, 'inside': 1299, 'insincere': 1300, 'insipid': 1301, 'insomniacs': 1302, 'inspiration': 1303, 'inspiring': 1304, 'instant': 1305, 'instead': 1306, 'instruments': 1307, 'insulin': 1308, 'insult': 1309, 'intangibles': 1310, 'integral': 1311, 'integration': 1312, 'intelligence': 1313, 'intelligent': 1314, 'intense': 1315, 'intensity': 1316, 'intentions': 1317, 'interacting': 1318, 'interest': 1319, 'interested': 1320, 'interesting': 1321, 'interim': 1322, 'interplay': 1323, 'interpretations': 1324, 'interview': 1325, 'intoning': 1326, 'intrigued': 1327, 'inventive': 1328, 'involved': 1329, 'involves': 1330, 'involving': 1331, 'iq': 1332, 'ireland': 1333, 'ironically': 1334, 'irons': 1335, 'ironside': 1336, 'irritating': 1337, 'ishioka': 1338, 'iso': 1339, 'issue': 1340, 'issues': 1341, 'istagey': 1342, 'italian': 1343, 'ive': 1344, 'jack': 1345, 'jaclyn': 1346, 'james': 1347, 'jamie': 1348, 'japanese': 1349, 'jason': 1350, 'jay': 1351, 'jealousy': 1352, 'jean': 1353, 'jennifer': 1354, 'jerky': 1355, 'jerry': 1356, 'jessica': 1357, 'jessice': 1358, 'jet': 1359, 'jim': 1360, 'jimmy': 1361, 'job': 1362, 'jobs': 1363, 'joe': 1364, 'john': 1365, 'joins': 1366, 'joke': 1367, 'jokes': 1368, 'jonah': 1369, 'jones': 1370, 'journey': 1371, 'joy': 1372, 'joyce': 1373, 'juano': 1374, 'judge': 1375, 'judging': 1376, 'judith': 1377, 'judo': 1378, 'julian': 1379, 'june': 1380, 'junk': 1381, 'junkyard': 1382, 'justice': 1383, 'jutland': 1384, 'kanaly': 1385, 'kathy': 1386, 'keep': 1387, 'keeps': 1388, 'keira': 1389, 'keith': 1390, 'kept': 1391, 'kevin': 1392, 'kid': 1393, 'kidnapped': 1394, 'kids': 1395, 'kieslowski': 1396, 'kill': 1397, 'killer': 1398, 'killing': 1399, 'killings': 1400, 'kind': 1401, 'kinda': 1402, 'kirk': 1403, 'kitchy': 1404, 'knew': 1405, 'knightley': 1406, 'knocked': 1407, 'know': 1408, 'known': 1409, 'knows': 1410, 'koteas': 1411, 'kris': 1412, 'kristoffersen': 1413, 'kudos': 1414, 'la': 1415, 'labute': 1416, 'lack': 1417, 'lacked': 1418, 'lacks': 1419, 'ladies': 1420, 'lady': 1421, 'lame': 1422, 'lance': 1423, 'landscapes': 1424, 'lane': 1425, 'lange': 1426, 'largely': 1427, 'laselva': 1428, 'lassie': 1429, 'last': 1430, 'lasting': 1431, 'latched': 1432, 'late': 1433, 'later': 1434, 'latest': 1435, 'latifa': 1436, 'latin': 1437, 'latter': 1438, 'laugh': 1439, 'laughable': 1440, 'laughed': 1441, 'laughs': 1442, 'layers': 1443, 'lazy': 1444, 'lead': 1445, 'leading': 1446, 'leap': 1447, 'learn': 1448, 'least': 1449, 'leave': 1450, 'leaves': 1451, 'leaving': 1452, 'lee': 1453, 'left': 1454, 'legal': 1455, 'legendary': 1456, 'length': 1457, 'leni': 1458, 'less': 1459, 'lesser': 1460, 'lestat': 1461, 'let': 1462, 'lets': 1463, 'letting': 1464, 'level': 1465, 'levels': 1466, 'lewis': 1467, 'lid': 1468, 'lie': 1469, 'lies': 1470, 'lieutenant': 1471, 'life': 1472, 'lifetime': 1473, 'light': 1474, 'lighting': 1475, 'like': 1476, 'liked': 1477, 'likes': 1478, 'lilli': 1479, 'lilt': 1480, 'limitations': 1481, 'limited': 1482, 'linda': 1483, 'line': 1484, 'linear': 1485, 'lines': 1486, 'lino': 1487, 'lion': 1488, 'list': 1489, 'literally': 1490, 'littered': 1491, 'little': 1492, 'lived': 1493, 'lives': 1494, 'living': 1495, 'loads': 1496, 'local': 1497, 'location': 1498, 'locations': 1499, 'loewenhielm': 1500, 'logic': 1501, 'london': 1502, 'loneliness': 1503, 'long': 1504, 'longer': 1505, 'look': 1506, 'looked': 1507, 'looking': 1508, 'looks': 1509, 'loose': 1510, 'loosely': 1511, 'lord': 1512, 'los': 1513, 'losing': 1514, 'lost': 1515, 'lot': 1516, 'lots': 1517, 'lousy': 1518, 'lovable': 1519, 'love': 1520, 'loved': 1521, 'lovely': 1522, 'loves': 1523, 'low': 1524, 'lower': 1525, 'loyalty': 1526, 'lucio': 1527, 'lucy': 1528, 'lugosi': 1529, 'lust': 1530, 'luv': 1531, 'lyrics': 1532, 'macbeth': 1533, 'machine': 1534, 'mad': 1535, 'made': 1536, 'magnificent': 1537, 'main': 1538, 'mainly': 1539, 'major': 1540, 'make': 1541, 'maker': 1542, 'makers': 1543, 'makes': 1544, 'making': 1545, 'male': 1546, 'males': 1547, 'malta': 1548, 'man': 1549, 'managed': 1550, 'manages': 1551, 'manna': 1552, 'mansonites': 1553, 'many': 1554, 'marbles': 1555, 'march': 1556, 'marine': 1557, 'marion': 1558, 'mark': 1559, 'marred': 1560, 'marriage': 1561, 'martin': 1562, 'masculine': 1563, 'masculinity': 1564, 'massive': 1565, 'master': 1566, 'masterful': 1567, 'masterpiece': 1568, 'masterpieces': 1569, 'material': 1570, 'matrix': 1571, 'matter': 1572, 'matthews': 1573, 'mature': 1574, 'may': 1575, 'maybe': 1576, 'mchattie': 1577, 'mclaglen': 1578, 'meagre': 1579, 'mean': 1580, 'meanders': 1581, 'meaning': 1582, 'meanings': 1583, 'meant': 1584, 'medical': 1585, 'mediocre': 1586, 'meld': 1587, 'melodrama': 1588, 'melville': 1589, 'member': 1590, 'members': 1591, 'memorable': 1592, 'memories': 1593, 'memorized': 1594, 'menace': 1595, 'menacing': 1596, 'mention': 1597, 'mercy': 1598, 'meredith': 1599, 'merit': 1600, 'mesmerising': 1601, 'mess': 1602, 'messages': 1603, 'meteorite': 1604, 'mexican': 1605, 'michael': 1606, 'mickey': 1607, 'microsoft': 1608, 'middle': 1609, 'might': 1610, 'mighty': 1611, 'mind': 1612, 'mindblowing': 1613, 'miner': 1614, 'mini': 1615, 'minor': 1616, 'minute': 1617, 'minutes': 1618, 'mirrormask': 1619, 'miserable': 1620, 'miserably': 1621, 'mishima': 1622, 'misplace': 1623, 'miss': 1624, 'missed': 1625, 'mistakes': 1626, 'miyazaki': 1627, 'modern': 1628, 'modest': 1629, 'mollusk': 1630, 'moment': 1631, 'moments': 1632, 'momentum': 1633, 'money': 1634, 'monica': 1635, 'monolog': 1636, 'monotonous': 1637, 'monster': 1638, 'monstrous': 1639, 'monumental': 1640, 'moral': 1641, 'morgan': 1642, 'morons': 1643, 'mostly': 1644, 'mother': 1645, 'motion': 1646, 'motivations': 1647, 'mountain': 1648, 'mouse': 1649, 'mouth': 1650, 'move': 1651, 'moved': 1652, 'movements': 1653, 'moves': 1654, 'movie': 1655, 'movies': 1656, 'moving': 1657, 'ms': 1658, 'much': 1659, 'muddled': 1660, 'muppets': 1661, 'murder': 1662, 'murdered': 1663, 'murdering': 1664, 'murky': 1665, 'music': 1666, 'musician': 1667, 'must': 1668, 'mystifying': 1669, 'n': 1670, 'naked': 1671, 'narration': 1672, 'narrative': 1673, 'nasty': 1674, 'national': 1675, 'nationalities': 1676, 'native': 1677, 'natural': 1678, 'nature': 1679, 'naughty': 1680, 'nearly': 1681, 'necklace': 1682, 'need': 1683, 'needed': 1684, 'needlessly': 1685, 'negative': 1686, 'negulesco': 1687, 'neighbour': 1688, 'neil': 1689, 'nerves': 1690, 'nervous': 1691, 'net': 1692, 'netflix': 1693, 'network': 1694, 'never': 1695, 'nevertheless': 1696, 'nevsky': 1697, 'new': 1698, 'next': 1699, 'nice': 1700, 'nicola': 1701, 'night': 1702, 'nimoy': 1703, 'nine': 1704, 'no': 1705, 'noble': 1706, 'nobody': 1707, 'noir': 1708, 'non': 1709, 'none': 1710, 'nonetheless': 1711, 'nonsense': 1712, 'nor': 1713, 'normally': 1714, 'northern': 1715, 'nostalgia': 1716, 'not': 1717, 'notable': 1718, 'notch': 1719, 'note': 1720, 'noteworthy': 1721, 'nothing': 1722, 'novella': 1723, 'number': 1724, 'numbers': 1725, 'nun': 1726, 'nuns': 1727, 'nurse': 1728, 'nut': 1729, 'nuts': 1730, 'obliged': 1731, 'obsessed': 1732, 'obvious': 1733, 'obviously': 1734, 'occasionally': 1735, 'occupied': 1736, 'occur': 1737, 'occurs': 1738, 'odd': 1739, 'offend': 1740, 'offensive': 1741, 'offer': 1742, 'offers': 1743, 'often': 1744, 'oh': 1745, 'okay': 1746, 'old': 1747, 'olde': 1748, 'older': 1749, 'ole': 1750, 'olivia': 1751, 'omit': 1752, 'one': 1753, 'ones': 1754, 'open': 1755, 'opened': 1756, 'opening': 1757, 'operas': 1758, 'opinion': 1759, 'ordeal': 1760, 'oriented': 1761, 'original': 1762, 'originality': 1763, 'origins': 1764, 'ortolani': 1765, 'oscar': 1766, 'others': 1767, 'otherwise': 1768, 'ought': 1769, 'outlandish': 1770, 'outlets': 1771, 'outside': 1772, 'outward': 1773, 'overacting': 1774, 'overall': 1775, 'overcome': 1776, 'overdue': 1777, 'overly': 1778, 'overs': 1779, 'overt': 1780, 'overwrought': 1781, 'owed': 1782, 'owls': 1783, 'owned': 1784, 'owns': 1785, 'oy': 1786, 'pace': 1787, 'paced': 1788, 'pacing': 1789, 'pack': 1790, 'paid': 1791, 'painful': 1792, 'painfully': 1793, 'paint': 1794, 'painted': 1795, 'pair': 1796, 'palance': 1797, 'pandering': 1798, 'pans': 1799, 'paolo': 1800, 'pap': 1801, 'paper': 1802, 'par': 1803, 'parents': 1804, 'park': 1805, 'parker': 1806, 'part': 1807, 'partaking': 1808, 'particular': 1809, 'particularly': 1810, 'parts': 1811, 'passed': 1812, 'passion': 1813, 'past': 1814, 'patent': 1815, 'pathetic': 1816, 'patriotism': 1817, 'paul': 1818, 'pay': 1819, 'peaking': 1820, 'pearls': 1821, 'peculiarity': 1822, 'pedestal': 1823, 'pencil': 1824, 'people': 1825, 'perabo': 1826, 'perfect': 1827, 'perfected': 1828, 'perfectly': 1829, 'performance': 1830, 'performances': 1831, 'perhaps': 1832, 'period': 1833, 'perplexing': 1834, 'person': 1835, 'personalities': 1836, 'personally': 1837, 'peter': 1838, 'pg': 1839, 'phantasm': 1840, 'phenomenal': 1841, 'philippa': 1842, 'phony': 1843, 'photograph': 1844, 'photography': 1845, 'phrase': 1846, 'physical': 1847, 'pi': 1848, 'picked': 1849, 'picture': 1850, 'pictures': 1851, 'piece': 1852, 'pieces': 1853, 'pile': 1854, 'pillow': 1855, 'pitch': 1856, 'pitiful': 1857, 'pixar': 1858, 'place': 1859, 'places': 1860, 'plain': 1861, 'plane': 1862, 'planned': 1863, 'plants': 1864, 'play': 1865, 'played': 1866, 'player': 1867, 'players': 1868, 'playing': 1869, 'plays': 1870, 'pleasant': 1871, 'pleased': 1872, 'pleaser': 1873, 'pleasing': 1874, 'pledge': 1875, 'plenty': 1876, 'plmer': 1877, 'plot': 1878, 'plug': 1879, 'plus': 1880, 'pm': 1881, 'poet': 1882, 'poetry': 1883, 'poignant': 1884, 'point': 1885, 'pointillistic': 1886, 'pointless': 1887, 'poised': 1888, 'poler': 1889, 'political': 1890, 'politically': 1891, 'politics': 1892, 'ponyo': 1893, 'poor': 1894, 'poorly': 1895, 'popcorn': 1896, 'popular': 1897, 'portrayal': 1898, 'portrayals': 1899, 'portrayed': 1900, 'portraying': 1901, 'positive': 1902, 'possible': 1903, 'possibly': 1904, 'post': 1905, 'potted': 1906, 'power': 1907, 'powerful': 1908, 'powerhouse': 1909, 'practical': 1910, 'practically': 1911, 'pray': 1912, 'precisely': 1913, 'predict': 1914, 'predictable': 1915, 'predictably': 1916, 'prejudice': 1917, 'prelude': 1918, 'premise': 1919, 'prepared': 1920, 'presence': 1921, 'presents': 1922, 'preservation': 1923, 'president': 1924, 'pretentious': 1925, 'pretext': 1926, 'pretty': 1927, 'previous': 1928, 'primal': 1929, 'primary': 1930, 'probably': 1931, 'problem': 1932, 'problems': 1933, 'proceedings': 1934, 'process': 1935, 'produce': 1936, 'produced': 1937, 'producer': 1938, 'producers': 1939, 'product': 1940, 'production': 1941, 'professionals': 1942, 'professor': 1943, 'progresses': 1944, 'promote': 1945, 'prompted': 1946, 'prone': 1947, 'propaganda': 1948, 'properly': 1949, 'proud': 1950, 'proudly': 1951, 'provided': 1952, 'provokes': 1953, 'provoking': 1954, 'ps': 1955, 'pseudo': 1956, 'psychological': 1957, 'psychotic': 1958, 'public': 1959, 'pull': 1960, 'pulling': 1961, 'pulls': 1962, 'punched': 1963, 'punches': 1964, 'punish': 1965, 'punishment': 1966, 'puppet': 1967, 'puppets': 1968, 'pure': 1969, 'purity': 1970, 'put': 1971, 'putting': 1972, 'puzzle': 1973, 'pyromaniac': 1974, 'q': 1975, 'qu': 1976, 'quaid': 1977, 'qualities': 1978, 'quality': 1979, 'question': 1980, 'questioning': 1981, 'quick': 1982, 'quicker': 1983, 'quiet': 1984, 'quinn': 1985, 'quite': 1986, 'r': 1987, 'race': 1988, 'racial': 1989, 'racism': 1990, 'radiant': 1991, 'raging': 1992, 'random': 1993, 'range': 1994, 'ranks': 1995, 'rare': 1996, 'rate': 1997, 'rated': 1998, 'rather': 1999, 'rating': 2000, 'ratings': 2001, 'raver': 2002, 'raw': 2003, 'ray': 2004, 'reactions': 2005, 'readers': 2006, 'reading': 2007, 'ready': 2008, 'real': 2009, 'realised': 2010, 'realistic': 2011, 'reality': 2012, 'realize': 2013, 'realized': 2014, 'really': 2015, 'reason': 2016, 'reasonable': 2017, 'reasons': 2018, 'receive': 2019, 'received': 2020, 'recent': 2021, 'recently': 2022, 'recommend': 2023, 'recommended': 2024, 'reconciliation': 2025, 'recover': 2026, 'recurring': 2027, 'redeemed': 2028, 'redeeming': 2029, 'reenactments': 2030, 'references': 2031, 'reflected': 2032, 'refreshing': 2033, 'regardless': 2034, 'regret': 2035, 'regrettable': 2036, 'regrettably': 2037, 'rejection': 2038, 'relate': 2039, 'related': 2040, 'relation': 2041, 'relations': 2042, 'relationship': 2043, 'relationships': 2044, 'relatively': 2045, 'relaxing': 2046, 'release': 2047, 'released': 2048, 'relief': 2049, 'relying': 2050, 'remaining': 2051, 'remake': 2052, 'remarkable': 2053, 'remember': 2054, 'reminded': 2055, 'remotely': 2056, 'removing': 2057, 'rendering': 2058, 'rendition': 2059, 'renowned': 2060, 'rent': 2061, 'repair': 2062, 'repeated': 2063, 'repeating': 2064, 'repeats': 2065, 'repertory': 2066, 'reporter': 2067, 'represents': 2068, 'require': 2069, 'rescue': 2070, 'researched': 2071, 'resounding': 2072, 'respecting': 2073, 'rest': 2074, 'restrained': 2075, 'result': 2076, 'results': 2077, 'resume': 2078, 'retarded': 2079, 'retreat': 2080, 'return': 2081, 'revealing': 2082, 'revenge': 2083, 'revere': 2084, 'reverse': 2085, 'review': 2086, 'reviewer': 2087, 'reviewers': 2088, 'reviews': 2089, 'rice': 2090, 'rickman': 2091, 'ridiculous': 2092, 'ridiculousness': 2093, 'right': 2094, 'riot': 2095, 'rips': 2096, 'rise': 2097, 'rita': 2098, 'rivalry': 2099, 'riveted': 2100, 'riz': 2101, 'road': 2102, 'robert': 2103, 'robotic': 2104, 'rochon': 2105, 'rocked': 2106, 'rocks': 2107, 'roeg': 2108, 'role': 2109, 'roles': 2110, 'roller': 2111, 'rolls': 2112, 'romantic': 2113, 'room': 2114, 'roosevelt': 2115, 'roth': 2116, 'rough': 2117, 'round': 2118, 'routine': 2119, 'row': 2120, 'rpg': 2121, 'rpger': 2122, 'rubbish': 2123, 'rubin': 2124, 'rumbles': 2125, 'run': 2126, 'running': 2127, 'ruthless': 2128, 'ryan': 2129, 'ryans': 2130, 'sabotages': 2131, 'sack': 2132, 'sacrifice': 2133, 'sad': 2134, 'said': 2135, 'sake': 2136, 'salesman': 2137, 'sam': 2138, 'sample': 2139, 'sand': 2140, 'sandra': 2141, 'sappiest': 2142, 'sarcophage': 2143, 'sat': 2144, 'satanic': 2145, 'savalas': 2146, 'savant': 2147, 'save': 2148, 'savor': 2149, 'saw': 2150, 'say': 2151, 'says': 2152, 'scale': 2153, 'scamp': 2154, 'scare': 2155, 'scared': 2156, 'scares': 2157, 'scary': 2158, 'scene': 2159, 'scenery': 2160, 'scenes': 2161, 'schilling': 2162, 'schizophrenic': 2163, 'school': 2164, 'schoolers': 2165, 'schrader': 2166, 'schultz': 2167, 'sci': 2168, 'science': 2169, 'scientist': 2170, 'score': 2171, 'scot': 2172, 'scream': 2173, 'screamy': 2174, 'screen': 2175, 'screened': 2176, 'screenplay': 2177, 'screenwriter': 2178, 'scrimm': 2179, 'script': 2180, 'scripted': 2181, 'scripting': 2182, 'scripts': 2183, 'sculpture': 2184, 'sea': 2185, 'seamless': 2186, 'seamlessly': 2187, 'sean': 2188, 'season': 2189, 'seat': 2190, 'second': 2191, 'secondary': 2192, 'secondly': 2193, 'see': 2194, 'seeing': 2195, 'seem': 2196, 'seemed': 2197, 'seems': 2198, 'seen': 2199, 'selections': 2200, 'self': 2201, 'sells': 2202, 'semi': 2203, 'senior': 2204, 'sense': 2205, 'senses': 2206, 'sensibility': 2207, 'sensitivities': 2208, 'sentiment': 2209, 'seperate': 2210, 'sequel': 2211, 'sequels': 2212, 'sequence': 2213, 'sequences': 2214, 'series': 2215, 'serious': 2216, 'seriously': 2217, 'served': 2218, 'set': 2219, 'sets': 2220, 'setting': 2221, 'settings': 2222, 'seuss': 2223, 'several': 2224, 'sex': 2225, 'shakespear': 2226, 'shakespears': 2227, 'shallow': 2228, 'shame': 2229, 'shameful': 2230, 'share': 2231, 'sharing': 2232, 'sharply': 2233, 'shatner': 2234, 'shattered': 2235, 'shed': 2236, 'sheer': 2237, 'shelf': 2238, 'shell': 2239, 'shelves': 2240, 'shenanigans': 2241, 'shepard': 2242, 'shined': 2243, 'shirley': 2244, 'shocking': 2245, 'shooting': 2246, 'short': 2247, 'shortlist': 2248, 'shot': 2249, 'shots': 2250, 'show': 2251, 'showcasing': 2252, 'showed': 2253, 'shows': 2254, 'shut': 2255, 'sibling': 2256, 'sick': 2257, 'side': 2258, 'sidelined': 2259, 'sign': 2260, 'significant': 2261, 'silent': 2262, 'silly': 2263, 'simmering': 2264, 'simplifying': 2265, 'simply': 2266, 'since': 2267, 'sincere': 2268, 'sing': 2269, 'singing': 2270, 'single': 2271, 'sinister': 2272, 'sink': 2273, 'sinking': 2274, 'sister': 2275, 'sisters': 2276, 'sit': 2277, 'sitcoms': 2278, 'site': 2279, 'sites': 2280, 'sits': 2281, 'situation': 2282, 'situations': 2283, 'skilled': 2284, 'skip': 2285, 'slackers': 2286, 'slavic': 2287, 'sleep': 2288, 'slideshow': 2289, 'slightest': 2290, 'slightly': 2291, 'slimy': 2292, 'sloppy': 2293, 'slow': 2294, 'slurs': 2295, 'smack': 2296, 'small': 2297, 'smart': 2298, 'smells': 2299, 'smile': 2300, 'smiling': 2301, 'smith': 2302, 'smoothly': 2303, 'snider': 2304, 'snow': 2305, 'soap': 2306, 'sobering': 2307, 'social': 2308, 'soldiers': 2309, 'sole': 2310, 'solid': 2311, 'solidifying': 2312, 'solving': 2313, 'someone': 2314, 'something': 2315, 'sometimes': 2316, 'somewhat': 2317, 'son': 2318, 'song': 2319, 'songs': 2320, 'soon': 2321, 'sophisticated': 2322, 'sorrentino': 2323, 'sorry': 2324, 'sort': 2325, 'soul': 2326, 'sound': 2327, 'sounded': 2328, 'sounds': 2329, 'soundtrack': 2330, 'sour': 2331, 'south': 2332, 'southern': 2333, 'space': 2334, 'spacek': 2335, 'spacey': 2336, 'span': 2337, 'speak': 2338, 'speaking': 2339, 'special': 2340, 'speed': 2341, 'spend': 2342, 'spent': 2343, 'spew': 2344, 'sphere': 2345, 'spiffy': 2346, 'splendid': 2347, 'spock': 2348, 'spoil': 2349, 'spoiled': 2350, 'spoiler': 2351, 'spoilers': 2352, 'spot': 2353, 'spy': 2354, 'squibs': 2355, 'stable': 2356, 'stage': 2357, 'stagy': 2358, 'stand': 2359, 'standout': 2360, 'stanwyck': 2361, 'star': 2362, 'starlet': 2363, 'starring': 2364, 'stars': 2365, 'start': 2366, 'started': 2367, 'starts': 2368, 'state': 2369, 'stay': 2370, 'stayed': 2371, 'stealing': 2372, 'steamboat': 2373, 'steele': 2374, 'step': 2375, 'stephen': 2376, 'stereotypes': 2377, 'stereotypically': 2378, 'steve': 2379, 'stewart': 2380, 'stick': 2381, 'still': 2382, 'stinker': 2383, 'stinks': 2384, 'stocking': 2385, 'stockings': 2386, 'stoic': 2387, 'store': 2388, 'stories': 2389, 'storm': 2390, 'story': 2391, 'storyline': 2392, 'storytelling': 2393, 'stowe': 2394, 'strange': 2395, 'stranger': 2396, 'stratus': 2397, 'straw': 2398, 'street': 2399, 'strident': 2400, 'string': 2401, 'strives': 2402, 'strokes': 2403, 'strong': 2404, 'struck': 2405, 'structure': 2406, 'struggle': 2407, 'stuart': 2408, 'student': 2409, 'students': 2410, 'studio': 2411, 'study': 2412, 'stuff': 2413, 'stunning': 2414, 'stupid': 2415, 'stupidity': 2416, 'style': 2417, 'stylized': 2418, 'sub': 2419, 'subject': 2420, 'subjects': 2421, 'sublime': 2422, 'sublimely': 2423, 'subplots': 2424, 'subtitles': 2425, 'subtle': 2426, 'subversive': 2427, 'subverting': 2428, 'succeeded': 2429, 'succeeds': 2430, 'success': 2431, 'suck': 2432, 'sucked': 2433, 'sucks': 2434, 'suffered': 2435, 'suffering': 2436, 'suggest': 2437, 'suggests': 2438, 'suited': 2439, 'sum': 2440, 'summary': 2441, 'sundays': 2442, 'super': 2443, 'superb': 2444, 'superbad': 2445, 'superbly': 2446, 'superficial': 2447, 'superlative': 2448, 'supernatural': 2449, 'supporting': 2450, 'supposed': 2451, 'supposedly': 2452, 'sure': 2453, 'surely': 2454, 'surf': 2455, 'surface': 2456, 'surprised': 2457, 'surprises': 2458, 'surprising': 2459, 'surprisingly': 2460, 'surrounding': 2461, 'surroundings': 2462, 'survivors': 2463, 'suspense': 2464, 'suspension': 2465, 'sven': 2466, 'swamp': 2467, 'sweep': 2468, 'sweet': 2469, 'switched': 2470, 'swords': 2471, 'sydney': 2472, 'sympathetic': 2473, 'syrupy': 2474, 'system': 2475, 'tacky': 2476, 'taelons': 2477, 'take': 2478, 'taken': 2479, 'takes': 2480, 'taking': 2481, 'tale': 2482, 'talent': 2483, 'talented': 2484, 'talents': 2485, 'talk': 2486, 'tanks': 2487, 'taped': 2488, 'tardis': 2489, 'task': 2490, 'taste': 2491, 'taxidermists': 2492, 'taylor': 2493, 'teacher': 2494, 'teaches': 2495, 'team': 2496, 'tear': 2497, 'tears': 2498, 'technically': 2499, 'teddy': 2500, 'tedium': 2501, 'teen': 2502, 'teenagers': 2503, 'teeth': 2504, 'telephone': 2505, 'television': 2506, 'tell': 2507, 'telly': 2508, 'temperaments': 2509, 'ten': 2510, 'tender': 2511, 'tension': 2512, 'tensions': 2513, 'terminology': 2514, 'terms': 2515, 'terrible': 2516, 'terribly': 2517, 'terrific': 2518, 'terror': 2519, 'th': 2520, 'thanks': 2521, 'theater': 2522, 'theatre': 2523, 'theatres': 2524, 'theatrical': 2525, 'theme': 2526, 'themes': 2527, 'therapy': 2528, 'thick': 2529, 'thing': 2530, 'things': 2531, 'think': 2532, 'thinking': 2533, 'thomerson': 2534, 'thoroughly': 2535, 'thorsen': 2536, 'though': 2537, 'thought': 2538, 'thoughts': 2539, 'thousand': 2540, 'thread': 2541, 'three': 2542, 'threshold': 2543, 'thrilled': 2544, 'thriller': 2545, 'thrillers': 2546, 'throughout': 2547, 'throwback': 2548, 'thrown': 2549, 'thug': 2550, 'thumper': 2551, 'thunderbirds': 2552, 'thus': 2553, 'ticker': 2554, 'tickets': 2555, 'tightly': 2556, 'time': 2557, 'timeless': 2558, 'timely': 2559, 'timers': 2560, 'times': 2561, 'timing': 2562, 'tiny': 2563, 'tired': 2564, 'title': 2565, 'titta': 2566, 'today': 2567, 'together': 2568, 'told': 2569, 'tolerable': 2570, 'tolerate': 2571, 'tom': 2572, 'tomorrow': 2573, 'tone': 2574, 'tongue': 2575, 'tonight': 2576, 'tons': 2577, 'tony': 2578, 'took': 2579, 'toons': 2580, 'top': 2581, 'tops': 2582, 'torture': 2583, 'tortured': 2584, 'total': 2585, 'totally': 2586, 'touch': 2587, 'touches': 2588, 'touching': 2589, 'tough': 2590, 'towards': 2591, 'towers': 2592, 'townsend': 2593, 'track': 2594, 'tract': 2595, 'traditional': 2596, 'traffic': 2597, 'trailer': 2598, 'train': 2599, 'tranquillity': 2600, 'transcend': 2601, 'transfers': 2602, 'translate': 2603, 'translating': 2604, 'trap': 2605, 'trash': 2606, 'trashy': 2607, 'treachery': 2608, 'treasure': 2609, 'treat': 2610, 'treatments': 2611, 'trek': 2612, 'tremendous': 2613, 'tremendously': 2614, 'tries': 2615, 'trilogy': 2616, 'trinity': 2617, 'trip': 2618, 'triumphed': 2619, 'trond': 2620, 'trooper': 2621, 'trouble': 2622, 'truck': 2623, 'true': 2624, 'truly': 2625, 'trumbull': 2626, 'trumpeter': 2627, 'truth': 2628, 'try': 2629, 'trying': 2630, 'trysts': 2631, 'tsunami': 2632, 'tuneful': 2633, 'turkey': 2634, 'turn': 2635, 'turned': 2636, 'turns': 2637, 'tv': 2638, 'twice': 2639, 'twirling': 2640, 'twist': 2641, 'twists': 2642, 'two': 2643, 'tying': 2644, 'type': 2645, 'typical': 2646, 'u': 2647, 'ue': 2648, 'ugliest': 2649, 'ugly': 2650, 'uhura': 2651, 'ultra': 2652, 'um': 2653, 'unaccompanied': 2654, 'unbearable': 2655, 'unbearably': 2656, 'unbelievable': 2657, 'uncalled': 2658, 'unconditional': 2659, 'unconvincing': 2660, 'underacting': 2661, 'underappreciated': 2662, 'underbite': 2663, 'underlines': 2664, 'underlying': 2665, 'underneath': 2666, 'underrated': 2667, 'understand': 2668, 'understanding': 2669, 'understated': 2670, 'understatement': 2671, 'understood': 2672, 'undertone': 2673, 'underwater': 2674, 'undoubtedly': 2675, 'uneasy': 2676, 'unemployed': 2677, 'unethical': 2678, 'unfaithful': 2679, 'unfolds': 2680, 'unforgettable': 2681, 'unfortunate': 2682, 'unfortunately': 2683, 'unfunny': 2684, 'unintentionally': 2685, 'uninteresting': 2686, 'union': 2687, 'unique': 2688, 'uniqueness': 2689, 'universal': 2690, 'universe': 2691, 'unless': 2692, 'unlockable': 2693, 'unmatched': 2694, 'unmitigated': 2695, 'unmoving': 2696, 'unnecessary': 2697, 'unneeded': 2698, 'unoriginal': 2699, 'unpleasant': 2700, 'unpredictability': 2701, 'unpredictable': 2702, 'unrealistic': 2703, 'unrecognizable': 2704, 'unrecommended': 2705, 'unremarkable': 2706, 'unrestrained': 2707, 'unsatisfactory': 2708, 'unwatchable': 2709, 'upa': 2710, 'uplifting': 2711, 'upper': 2712, 'ups': 2713, 'uptight': 2714, 'ursula': 2715, 'us': 2716, 'use': 2717, 'used': 2718, 'user': 2719, 'uses': 2720, 'using': 2721, 'ussr': 2722, 'usual': 2723, 'utter': 2724, 'utterly': 2725, 'v': 2726, 'valentine': 2727, 'value': 2728, 'values': 2729, 'vampire': 2730, 'vandiver': 2731, 'variation': 2732, 'vehicles': 2733, 'ventura': 2734, 'verbal': 2735, 'verbatim': 2736, 'versatile': 2737, 'version': 2738, 'versus': 2739, 'vessel': 2740, 'veteran': 2741, 'vey': 2742, 'vibe': 2743, 'victor': 2744, 'video': 2745, 'view': 2746, 'viewer': 2747, 'viewing': 2748, 'views': 2749, 'villain': 2750, 'villains': 2751, 'violence': 2752, 'violin': 2753, 'virtue': 2754, 'virus': 2755, 'vision': 2756, 'visual': 2757, 'visually': 2758, 'vitally': 2759, 'vivian': 2760, 'vivid': 2761, 'vocal': 2762, 'voice': 2763, 'volatile': 2764, 'volcano': 2765, 'vomit': 2766, 'vomited': 2767, 'voyage': 2768, 'vulcan': 2769, 'waiting': 2770, 'waitress': 2771, 'walk': 2772, 'walked': 2773, 'wall': 2774, 'want': 2775, 'wanted': 2776, 'wanting': 2777, 'wants': 2778, 'war': 2779, 'warmth': 2780, 'warn': 2781, 'warning': 2782, 'wartime': 2783, 'warts': 2784, 'washed': 2785, 'washing': 2786, 'waste': 2787, 'wasted': 2788, 'waster': 2789, 'wasting': 2790, 'watch': 2791, 'watchable': 2792, 'watched': 2793, 'watching': 2794, 'water': 2795, 'watkins': 2796, 'watson': 2797, 'wave': 2798, 'way': 2799, 'waylaid': 2800, 'wayne': 2801, 'ways': 2802, 'wb': 2803, 'weak': 2804, 'weaker': 2805, 'weariness': 2806, 'weaving': 2807, 'website': 2808, 'wedding': 2809, 'weight': 2810, 'weird': 2811, 'well': 2812, 'welsh': 2813, 'went': 2814, 'whatever': 2815, 'whatsoever': 2816, 'whenever': 2817, 'whether': 2818, 'whine': 2819, 'whiny': 2820, 'white': 2821, 'whites': 2822, 'whoever': 2823, 'whole': 2824, 'wholesome': 2825, 'wide': 2826, 'widmark': 2827, 'wife': 2828, 'wih': 2829, 'wild': 2830, 'wilkinson': 2831, 'william': 2832, 'willie': 2833, 'wily': 2834, 'win': 2835, 'wind': 2836, 'wise': 2837, 'wish': 2838, 'within': 2839, 'without': 2840, 'witticisms': 2841, 'witty': 2842, 'woa': 2843, 'women': 2844, 'wonder': 2845, 'wondered': 2846, 'wonderful': 2847, 'wonderfully': 2848, 'wong': 2849, 'wont': 2850, 'woo': 2851, 'wooden': 2852, 'word': 2853, 'words': 2854, 'work': 2855, 'worked': 2856, 'working': 2857, 'works': 2858, 'world': 2859, 'worry': 2860, 'worse': 2861, 'worst': 2862, 'worth': 2863, 'worthless': 2864, 'worthwhile': 2865, 'worthy': 2866, 'would': 2867, 'wouldnt': 2868, 'woven': 2869, 'wow': 2870, 'wrap': 2871, 'write': 2872, 'writer': 2873, 'writers': 2874, 'writing': 2875, 'written': 2876, 'wrong': 2877, 'wrote': 2878, 'x': 2879, 'yardley': 2880, 'yawn': 2881, 'yeah': 2882, 'year': 2883, 'years': 2884, 'yelps': 2885, 'yes': 2886, 'yet': 2887, 'young': 2888, 'younger': 2889, 'youthful': 2890, 'youtube': 2891, 'yun': 2892, 'z': 2893, 'zillion': 2894, 'zombie': 2895, 'zombiez': 2896}\n"
     ]
    }
   ],
   "source": [
    "def fit(dataset):\n",
    "    storage_set = set()\n",
    "    for document in dataset:\n",
    "        for word in document.split(\" \"):\n",
    "            storage_set.add(word)\n",
    "    storage_set = sorted(list(storage_set))\n",
    "    voc = {j:i for i,j in enumerate(storage_set)}\n",
    "    return voc\n",
    "\n",
    "vocab =  fit(corpus)\n",
    "print(vocab)\n",
    "vocab_list = list(vocab.keys())\n",
    "# # print(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aailiyah': 6.922918004572872, 'abandoned': 6.922918004572872, 'abroad': 6.922918004572872, 'abstruse': 6.922918004572872, 'academy': 6.922918004572872, 'accents': 6.922918004572872, 'accessible': 6.922918004572872, 'acclaimed': 6.922918004572872, 'accolades': 6.922918004572872, 'accurate': 6.922918004572872, 'accurately': 6.922918004572872, 'achille': 6.922918004572872, 'ackerman': 6.922918004572872, 'actions': 6.922918004572872, 'adams': 6.922918004572872, 'add': 6.922918004572872, 'added': 6.922918004572872, 'admins': 6.922918004572872, 'admiration': 6.922918004572872, 'admitted': 6.922918004572872, 'adrift': 6.922918004572872, 'adventure': 6.922918004572872, 'aesthetically': 6.922918004572872, 'affected': 6.922918004572872, 'affleck': 6.922918004572872, 'afternoon': 6.922918004572872, 'aged': 6.922918004572872, 'ages': 6.922918004572872, 'agree': 6.922918004572872, 'agreed': 6.922918004572872, 'aimless': 6.922918004572872, 'aired': 6.922918004572872, 'akasha': 6.922918004572872, 'akin': 6.922918004572872, 'alert': 6.922918004572872, 'alike': 6.922918004572872, 'allison': 6.922918004572872, 'allow': 6.922918004572872, 'allowing': 6.922918004572872, 'alongside': 6.922918004572872, 'amateurish': 6.922918004572872, 'amaze': 6.922918004572872, 'amazed': 6.922918004572872, 'amazingly': 6.922918004572872, 'amusing': 6.922918004572872, 'amust': 6.922918004572872, 'anatomist': 6.922918004572872, 'angel': 6.922918004572872, 'angela': 6.922918004572872, 'angelina': 6.922918004572872}\n"
     ]
    }
   ],
   "source": [
    "def computeIDF(vocabulary, dataset):\n",
    "    idf_val = dict()\n",
    "    for word in vocabulary:\n",
    "        count = 0\n",
    "        for doc in dataset:\n",
    "            if word in doc.split(' '):\n",
    "                count += 1\n",
    "                \n",
    "        value = 1 + math.log ((1 + (len(dataset))) / (1 + count))\n",
    "        idf_val[word] = value\n",
    "    return idf_val\n",
    "\n",
    "IDF = computeIDF(vocab_list, corpus)\n",
    "# sort IDF according to the values in decending order and limit it to top 50 values\n",
    "sorted_idf = {k: v for k, v in sorted(IDF.items(), key=lambda item: item[1], reverse=True)[:50]}\n",
    "print(sorted_idf)\n",
    "# print(sorted(sorted_idf))\n",
    "# sorted_vocab = (sorted_idf.keys())\n",
    "# print(sorted_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 30)\t1.0\n",
      "  (68, 24)\t1.0\n",
      "  (72, 29)\t1.0\n",
      "  (74, 31)\t1.0\n",
      "  (119, 33)\t1.0\n",
      "  (135, 3)\t0.37796447300922725\n",
      "  (135, 10)\t0.37796447300922725\n",
      "  (135, 18)\t0.37796447300922725\n",
      "  (135, 20)\t0.37796447300922725\n",
      "  (135, 36)\t0.37796447300922725\n",
      "  (135, 40)\t0.37796447300922725\n",
      "  (135, 41)\t0.37796447300922725\n",
      "  (176, 49)\t1.0\n",
      "  (181, 13)\t1.0\n",
      "  (192, 21)\t1.0\n",
      "  (193, 23)\t1.0\n",
      "  (216, 2)\t1.0\n",
      "  (222, 47)\t1.0\n",
      "  (225, 19)\t1.0\n",
      "  (227, 17)\t1.0\n",
      "  (241, 44)\t1.0\n",
      "  (270, 1)\t1.0\n",
      "  (290, 25)\t1.0\n",
      "  (333, 26)\t1.0\n",
      "  (334, 15)\t1.0\n",
      "  (341, 43)\t1.0\n",
      "  (344, 42)\t1.0\n",
      "  (348, 8)\t1.0\n",
      "  (377, 37)\t1.0\n",
      "  (409, 5)\t1.0\n",
      "  (430, 39)\t1.0\n",
      "  (457, 45)\t1.0\n",
      "  (461, 4)\t1.0\n",
      "  (465, 38)\t1.0\n",
      "  (475, 35)\t1.0\n",
      "  (493, 6)\t1.0\n",
      "  (500, 48)\t1.0\n",
      "  (548, 0)\t0.7071067811865475\n",
      "  (548, 32)\t0.7071067811865475\n",
      "  (608, 14)\t1.0\n",
      "  (612, 11)\t1.0\n",
      "  (620, 46)\t1.0\n",
      "  (632, 7)\t1.0\n",
      "  (644, 12)\t0.7071067811865475\n",
      "  (644, 27)\t0.7071067811865475\n",
      "  (664, 28)\t1.0\n",
      "  (667, 22)\t1.0\n",
      "  (691, 34)\t1.0\n",
      "  (697, 9)\t1.0\n",
      "  (722, 16)\t1.0\n"
     ]
    }
   ],
   "source": [
    "def transform(dataset,vocabulary, idf_values):\n",
    "    \n",
    "    idf_dict = {}\n",
    "    # create a dictionary of vocabulary words and its dimensions\n",
    "    vocab_dim = {word:dimension for dimension,word in enumerate(vocabulary)}\n",
    "    \n",
    "    \n",
    "    rows = []\n",
    "    columns = []\n",
    "    values = []\n",
    "    \n",
    "    for idx,val in enumerate(vocabulary):\n",
    "        idf_dict[val] = idf_values[val]\n",
    "        \n",
    "        \n",
    "    for idx, doc in enumerate(dataset):\n",
    "        N = len([word for word in doc.split(' ')])\n",
    "        word_freq = dict(Counter(doc.split(' ')))\n",
    "        tf = {key:float(val/N) for key,val in word_freq.items()}\n",
    "        for word, norm_freq in tf.items():\n",
    "            if len(word) < 2:\n",
    "                continue;\n",
    "            col_index = vocab_dim.get(word, -1)\n",
    "            if col_index !=-1:\n",
    "                rows.append(idx)\n",
    "                columns.append(col_index)\n",
    "                idf = idf_dict[word]\n",
    "                values.append(norm_freq * idf)\n",
    "    return normalize(csr_matrix((values, (rows,columns)), shape=(len(dataset),len(vocabulary))), norm='l2');\n",
    "\n",
    "\n",
    "output = (transform(dataset=corpus, vocabulary=sorted_idf, idf_values=IDF))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50)\n",
      "[[0.         0.         0.         0.37796447 0.         0.\n",
      "  0.         0.         0.         0.         0.37796447 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.37796447 0.         0.37796447 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.37796447 0.         0.         0.         0.37796447 0.37796447\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(output[0].shape)\n",
    "print(output[135].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
